{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25678\\anaconda3\\envs\\carRun\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_steering(datadir, data):\n",
    "    image_path = []\n",
    "    steering = []\n",
    "    for i in range(len(data)):\n",
    "        indexed_data = data.iloc[i]\n",
    "        center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]\n",
    "        image_path.append(os.path.join(datadir, center.strip()))\n",
    "        steering.append(float(indexed_data[3]))\n",
    "        # left image append\n",
    "        image_path.append(os.path.join(datadir,left.strip()))\n",
    "        steering.append(float(indexed_data[3])+0.15)\n",
    "        # right image append\n",
    "        image_path.append(os.path.join(datadir,right.strip()))\n",
    "        steering.append(float(indexed_data[3])-0.15)\n",
    "    image_paths = np.asarray(image_path)\n",
    "    steerings = np.asarray(steering)\n",
    "    return image_paths, steerings\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan(image):\n",
    "    pan = iaa.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "    image = pan.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def img_random_brightness(image):\n",
    "    brightness = iaa.Multiply((0.2, 1.2))\n",
    "    image = brightness.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def zoom(image):\n",
    "    zoom = iaa.Affine(scale=(1, 1.3))\n",
    "    image = zoom.augment_image(image)\n",
    "    return image\n",
    "\n",
    "def img_random_flip(image, steering_angle):\n",
    "    image = cv2.flip(image,1) # one for horizontal flip\n",
    "    steering_angle =- steering_angle\n",
    "    return image,steering_angle\n",
    "    \n",
    "def random_augment(image, steering_angle):\n",
    "    image = mpimg.imread(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = pan(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = zoom(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = img_random_brightness(image)\n",
    "    if np.random.rand() < 0.5:\n",
    "        image, steering_angle = img_random_flip(image, steering_angle)\n",
    "    \n",
    "    return image, steering_angle\n",
    "\n",
    "def img_preprocess(img):\n",
    "    img = img[60:135,:,:]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DrivingImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, steering_ang, transform=None):\n",
    "        self.img_paths = image_paths\n",
    "        self.steering_angs = steering_ang\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = mpimg.imread(img_path)\n",
    "        img = img_preprocess(img)\n",
    "        img = img.astype(np.uint8)\n",
    "        steering = self.steering_angs[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            # img = img.to(dtype=torch.long)\n",
    "            steering = torch.tensor(steering)\n",
    "            steering = torch.tensor([steering.to(dtype=torch.float32)])\n",
    "\n",
    "        # print('steering: ',steering.shape)\n",
    "        return img, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class nvidia_model(nn.Module):\n",
    "    in_planes = [3, 24, 36, 48, 64, 64, 1152, 100, 50, 10, 1]\n",
    "    kernel_size = [5, 5, 5, 3, 3]\n",
    "    dropout_p = [0.45, 0.4, 0.4]\n",
    "    def __init__(self):\n",
    "        super(nvidia_model, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv1 = nn.Conv2d(self.in_planes[0], self.in_planes[1], self.kernel_size[0], stride=2)\n",
    "        self.conv2 = nn.Conv2d(self.in_planes[1], self.in_planes[2], self.kernel_size[1], stride=2)\n",
    "        self.conv3 = nn.Conv2d(self.in_planes[2], self.in_planes[3], self.kernel_size[2], stride=2)\n",
    "        self.conv4 = nn.Conv2d(self.in_planes[3], self.in_planes[4], self.kernel_size[3])\n",
    "        self.conv5 = nn.Conv2d(self.in_planes[4], self.in_planes[5], self.kernel_size[4])\n",
    "        self.dropout1 = nn.Dropout(p=self.dropout_p[0])\n",
    "        self.fc1 = nn.Linear(self.in_planes[6], self.in_planes[7])\n",
    "        self.dropout2 = nn.Dropout(p=self.dropout_p[1])\n",
    "        self.fc2 = nn.Linear(self.in_planes[7], self.in_planes[8])\n",
    "        self.dropout3 = nn.Dropout(p=self.dropout_p[2])\n",
    "        self.fc3 = nn.Linear(self.in_planes[8], self.in_planes[9])\n",
    "        self.output = nn.Linear(self.in_planes[9], self.in_planes[10])\n",
    "\n",
    "    # def print_layer(self, layer):\n",
    "    #     print(layer.shape)\n",
    "    #     print(type(layer))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # self.print_layer(x)\n",
    "        out = self.bn1(x)\n",
    "        # self.print_layer(out)\n",
    "        out = F.relu(self.conv1(out))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = F.relu(self.conv5(out))\n",
    "        out = self.dropout1(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout3(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "term_width = 80 \n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Setup time measurement for training epoch\n",
    "    _tTrainAcc = 0\n",
    "    _cnt = 0\n",
    "    _topAccu = 0\n",
    "    _tCommAccu = 0\n",
    "    _tComputeAccu = 0\n",
    "    _tBegin = time.perf_counter()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        _tTrainStart = time.perf_counter()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # print('Finish Copying data into GPU')\n",
    "        # print('Test: ',targets.shape)\n",
    "        # print(inputs.dtype)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        _tCommStart = time.perf_counter()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # torch.cuda.synchronize()\n",
    "        \n",
    "        _tTrainEnd = time.perf_counter()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "        if not verboseFlag:\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.5f'\n",
    "                    % (train_loss/(batch_idx+1)))\n",
    "        _tTrainAcc += _tTrainEnd - _tTrainStart\n",
    "        _tCommAccu += _tTrainEnd- _tCommStart\n",
    "        _tComputeAccu += _tCommStart - _tTrainStart\n",
    "\n",
    "    _tEnd = time.perf_counter()\n",
    "    totalTime = _tEnd - _tBegin\n",
    "    trainTime = _tTrainAcc\n",
    "    commTime = _tCommAccu\n",
    "    computeTime = _tComputeAccu\n",
    "    loadTime = totalTime - trainTime\n",
    "    return train_loss, trainTime, totalTime, loadTime, commTime, computeTime\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_loss\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "        if not verboseFlag:\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.5f'\n",
    "                    % (test_loss/(batch_idx+1)))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if loss < best_loss:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nvidia_model()\n",
    "# summary(model, (3,66,200), batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir):\n",
    "    columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']\n",
    "    data = pd.read_csv(os.path.join(datadir, 'driving_log.csv'), names = columns)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    data.head()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_Dataset(Dir, batch):\n",
    "    transform_train = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    transform_valid = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    data = load_data(Dir)\n",
    "    image_paths, steerings = load_img_steering(Dir + '/IMG', data)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(image_paths, steerings, test_size=0.2)\n",
    "    print('Training Samples: {}\\nValid Samples: {}'.format(len(X_train), len(X_valid)))\n",
    "    Q = math.floor(len(X_train)/batch)\n",
    "    trainset = DrivingImageDataset(X_train, y_train, transform_train)\n",
    "    testset = DrivingImageDataset(X_valid, y_valid, transform_valid)\n",
    "    return trainset, testset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing Data\n",
      "Training Samples: 7300\n",
      "Valid Samples: 1826\n",
      "==> Building Model\n",
      "Start training using cuda\n",
      "\n",
      "Epoch: 0\n",
      " [===============================================================>.]  Step: 211ms | Tot: 15s494ms | Loss: 0.027 37/37 \n",
      " [=============================================================>...]  Step: 3s558ms | Tot: 19s53ms | Loss: 0.023 19/19 \n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datadir = '2'\n",
    "    verboseFlag = False\n",
    "    batch = 200\n",
    "    epochs = 1\n",
    "    worker_nums = 0\n",
    "    best_loss = 1000\n",
    "    print('==> Preparing Data')\n",
    "    trainset, testset = gen_Dataset(datadir, batch)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size = batch, shuffle=True, num_workers=worker_nums\n",
    "    )\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size = 100, shuffle=True, num_workers=worker_nums\n",
    "    )\n",
    "\n",
    "    print('==> Building Model')\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    print('Start training using', device)\n",
    "        \n",
    "    net = nvidia_model()\n",
    "    # net = net.double()\n",
    "    # summary(net)\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net =torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "    for epoch in range(0, epochs):\n",
    "        trainPerf = train(epoch)\n",
    "        test(epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carRun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cbd554e0a626d5b0dc8f6d70d23ade949fe63ff87b5e7e2bdb45ce904d97dac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
